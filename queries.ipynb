{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import firebase_admin\n",
    "from firebase_admin import credentials\n",
    "from firebase_admin import firestore\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "# Firebase project's credentials file\n",
    "cred = credentials.Certificate(\"service.json\")\n",
    "if not firebase_admin._apps:\n",
    "    firebase_admin.initialize_app(cred)\n",
    "else:\n",
    "    firebase_admin.get_app()\n",
    "\n",
    "db = firestore.client()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Iceberg query*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12611 : {'AvgPressure': 1001.0, 'WindSpeed9am': 13.0, 'RainToday': 'No', 'Temp3pm': 46.7, 'Pressure3pm': 998.1, 'Humidity9am': 30.0, 'WindGustDir': 'SSW', 'WindDir9am': 'NNE', 'Temp9am': 32.9, 'MinTemp': 27.8, 'Rainfall': 0.0, 'AvgTemp': 37.55, 'MaxTemp': 47.3, 'Location': 'Moree', 'AvgRainfall': 0.0, 'RainTomorrow': 'No', 'WindSpeed3pm': 28.0, 'Date': '2017-02-12', 'WindDir3pm': 'NW', 'WindGustSpeed': 67.0, 'Pressure9am': 1003.9, 'AvgHumidity': 20.0, 'Humidity3pm': 10.0, 'AvgWind': 36.0}\n",
      "11732 : {'AvgPressure': 998.9, 'WindSpeed9am': 33.0, 'RainToday': 'No', 'Temp3pm': 45.8, 'Pressure3pm': 995.9, 'Humidity9am': 36.0, 'WindGustDir': 'WSW', 'WindDir9am': 'N', 'Temp9am': 33.4, 'MinTemp': 28.3, 'Rainfall': 0.0, 'AvgTemp': 37.8, 'MaxTemp': 47.3, 'Location': 'Moree', 'AvgRainfall': 0.0, 'RainTomorrow': 'No', 'WindSpeed3pm': 33.0, 'Date': '2014-01-03', 'WindDir3pm': 'WNW', 'WindGustSpeed': 61.0, 'Pressure9am': 1001.9, 'AvgHumidity': 20.5, 'Humidity3pm': 5.0, 'AvgWind': 42.333333333333336}\n",
      "7448 : {'AvgPressure': 1006.8, 'WindSpeed9am': 19.0, 'RainToday': 'No', 'Temp3pm': 45.2, 'Pressure3pm': 1005.0, 'Humidity9am': 18.0, 'WindGustDir': 'N', 'WindDir9am': 'NNW', 'Temp9am': 36.3, 'MinTemp': 29.4, 'Rainfall': 0.0, 'AvgTemp': 38.0, 'MaxTemp': 46.6, 'Location': 'Cobar', 'AvgRainfall': 0.0, 'RainTomorrow': 'No', 'WindSpeed3pm': 19.0, 'Date': '2017-02-11', 'WindDir3pm': 'W', 'WindGustSpeed': 48.0, 'Pressure9am': 1008.6, 'AvgHumidity': 13.0, 'Humidity3pm': 8.0, 'AvgWind': 28.666666666666668}\n",
      "4672 : {'AvgPressure': 1004.95, 'WindSpeed9am': 9.0, 'RainToday': 'No', 'Temp3pm': 43.3, 'Pressure3pm': 1002.0, 'Humidity9am': 90.0, 'WindGustDir': 'S', 'WindDir9am': 'N', 'Temp9am': 25.5, 'MinTemp': 21.5, 'Rainfall': 0.0, 'AvgTemp': 33.95, 'MaxTemp': 46.4, 'Location': 'BadgerysCreek', 'AvgRainfall': 0.0, 'RainTomorrow': 'No', 'WindSpeed3pm': 7.0, 'Date': '2017-02-11', 'WindDir3pm': 'ENE', 'WindGustSpeed': 39.0, 'Pressure9am': 1007.9, 'AvgHumidity': 60.0, 'Humidity3pm': 30.0, 'AvgWind': 18.33333333333333}\n",
      "19232 : {'AvgPressure': 1000.3, 'WindSpeed9am': 2.0, 'RainToday': 'No', 'Temp3pm': 45.9, 'Pressure3pm': 997.7, 'Humidity9am': 66.0, 'WindGustDir': 'SSE', 'WindDir9am': 'ENE', 'Temp9am': 27.7, 'MinTemp': 19.7, 'Rainfall': 0.0, 'AvgTemp': 33.05, 'MaxTemp': 46.4, 'Location': 'Richmond', 'AvgRainfall': 0.0, 'RainTomorrow': 'No', 'WindSpeed3pm': 26.0, 'Date': '2013-01-18', 'WindDir3pm': 'W', 'WindGustSpeed': 65.0, 'Pressure9am': 1002.9, 'AvgHumidity': 40.0, 'Humidity3pm': 14.0, 'AvgWind': 31.0}\n"
     ]
    }
   ],
   "source": [
    "'''the results to only include documents from the past 5 years, \n",
    "    orders the results by MaxTemp in descending order, \n",
    "    and returns only the top 10 results.'''\n",
    "\n",
    "# query = db.collection('weather_data') \\\n",
    "#            .where('Date', '>=', '2016-04-02') \\\n",
    "#            .order_by('MaxTemp', direction=firestore.Query.DESCENDING) \\\n",
    "#            .order_by('Date') \\\n",
    "#            .limit(10)\n",
    "\n",
    "\n",
    "# results = query.stream()\n",
    "\n",
    "# for doc in results:\n",
    "#     print(f'{doc.id} => {doc.to_dict()}')\n",
    "\n",
    "start_date = datetime.datetime(2012, 1, 1)\n",
    "end_date = datetime.datetime(2023, 4, 2)\n",
    "\n",
    "query = db.collection('weather_data') \\\n",
    "           .order_by('MaxTemp', direction=firestore.Query.DESCENDING) \\\n",
    "           .limit(5)\n",
    "\n",
    "results = query.stream()\n",
    "\n",
    "for doc in results:\n",
    "    doc_date = doc.to_dict()['Date']\n",
    "    date_obj = datetime.datetime.strptime(doc_date, '%Y-%m-%d')\n",
    "    if start_date <= date_obj <= end_date:\n",
    "        print(f'{doc.id} : {doc.to_dict()}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "windowing query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "RetryError",
     "evalue": "Deadline of 300.0s exceeded while calling target function, last exception: 429 Quota exceeded.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_MultiThreadedRendezvous\u001b[0m                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/google/api_core/grpc_helpers.py:162\u001b[0m, in \u001b[0;36m_wrap_stream_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m     prefetch_first \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(callable_, \u001b[39m\"\u001b[39m\u001b[39m_prefetch_first_result_\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m--> 162\u001b[0m     \u001b[39mreturn\u001b[39;00m _StreamingResponseIterator(\n\u001b[1;32m    163\u001b[0m         result, prefetch_first_result\u001b[39m=\u001b[39;49mprefetch_first\n\u001b[1;32m    164\u001b[0m     )\n\u001b[1;32m    165\u001b[0m \u001b[39mexcept\u001b[39;00m grpc\u001b[39m.\u001b[39mRpcError \u001b[39mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/google/api_core/grpc_helpers.py:88\u001b[0m, in \u001b[0;36m_StreamingResponseIterator.__init__\u001b[0;34m(self, wrapped, prefetch_first_result)\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[39mif\u001b[39;00m prefetch_first_result:\n\u001b[0;32m---> 88\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stored_first_result \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wrapped)\n\u001b[1;32m     89\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m     90\u001b[0m     \u001b[39m# It is possible the wrapped method isn't an iterable (a grpc.Call\u001b[39;00m\n\u001b[1;32m     91\u001b[0m     \u001b[39m# for instance). If this happens don't store the first result.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/grpc/_channel.py:426\u001b[0m, in \u001b[0;36m_Rendezvous.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__next__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 426\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/grpc/_channel.py:826\u001b[0m, in \u001b[0;36m_MultiThreadedRendezvous._next\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    825\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state\u001b[39m.\u001b[39mcode \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 826\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "\u001b[0;31m_MultiThreadedRendezvous\u001b[0m: <_MultiThreadedRendezvous of RPC that terminated with:\n\tstatus = StatusCode.RESOURCE_EXHAUSTED\n\tdetails = \"Quota exceeded.\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer ipv4:172.217.1.10:443 {created_time:\"2023-04-03T16:49:06.296281-04:00\", grpc_status:8, grpc_message:\"Quota exceeded.\"}\"\n>",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mResourceExhausted\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/google/api_core/retry.py:191\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, **kwargs)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 191\u001b[0m     \u001b[39mreturn\u001b[39;00m target()\n\u001b[1;32m    193\u001b[0m \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m    194\u001b[0m \u001b[39m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/google/api_core/timeout.py:120\u001b[0m, in \u001b[0;36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout \u001b[39m-\u001b[39m time_since_first_attempt)\n\u001b[0;32m--> 120\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/google/api_core/grpc_helpers.py:166\u001b[0m, in \u001b[0;36m_wrap_stream_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[39mexcept\u001b[39;00m grpc\u001b[39m.\u001b[39mRpcError \u001b[39mas\u001b[39;00m exc:\n\u001b[0;32m--> 166\u001b[0m     \u001b[39mraise\u001b[39;00m exceptions\u001b[39m.\u001b[39mfrom_grpc_error(exc) \u001b[39mfrom\u001b[39;00m \u001b[39mexc\u001b[39;00m\n",
      "\u001b[0;31mResourceExhausted\u001b[0m: 429 Quota exceeded.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRetryError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m'''calculates the rolling average maximum temperature \u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m    over a 7-day window for each location'''\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39m# Query all documents in the \"weather_data\" collection\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m docs \u001b[39m=\u001b[39m db\u001b[39m.\u001b[39;49mcollection_group(\u001b[39m\"\u001b[39;49m\u001b[39mweather_data\u001b[39;49m\u001b[39m\"\u001b[39;49m)\u001b[39m.\u001b[39;49mget()\n\u001b[1;32m      7\u001b[0m \u001b[39m# Convert the documents to a pandas DataFrame\u001b[39;00m\n\u001b[1;32m      8\u001b[0m data \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/google/cloud/firestore_v1/query.py:172\u001b[0m, in \u001b[0;36mQuery.get\u001b[0;34m(self, transaction, retry, timeout)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[39mif\u001b[39;00m is_limited_to_last:\n\u001b[1;32m    170\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mreversed\u001b[39m(\u001b[39mlist\u001b[39m(result))\n\u001b[0;32m--> 172\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39;49m(result)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/google/cloud/firestore_v1/query.py:287\u001b[0m, in \u001b[0;36mQuery.stream\u001b[0;34m(self, transaction, retry, timeout)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstream\u001b[39m(\n\u001b[1;32m    252\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    253\u001b[0m     transaction\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    254\u001b[0m     retry: retries\u001b[39m.\u001b[39mRetry \u001b[39m=\u001b[39m gapic_v1\u001b[39m.\u001b[39mmethod\u001b[39m.\u001b[39mDEFAULT,\n\u001b[1;32m    255\u001b[0m     timeout: \u001b[39mfloat\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    256\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Generator[document\u001b[39m.\u001b[39mDocumentSnapshot, Any, \u001b[39mNone\u001b[39;00m]:\n\u001b[1;32m    257\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Read the documents in the collection that match this query.\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \n\u001b[1;32m    259\u001b[0m \u001b[39m    This sends a ``RunQuery`` RPC and then returns an iterator which\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[39m        The next document that fulfills the query.\u001b[39;00m\n\u001b[1;32m    286\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 287\u001b[0m     response_iterator, expected_prefix \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_stream_iterator(\n\u001b[1;32m    288\u001b[0m         transaction,\n\u001b[1;32m    289\u001b[0m         retry,\n\u001b[1;32m    290\u001b[0m         timeout,\n\u001b[1;32m    291\u001b[0m     )\n\u001b[1;32m    293\u001b[0m     last_snapshot \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    295\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/google/cloud/firestore_v1/query.py:221\u001b[0m, in \u001b[0;36mQuery._get_stream_iterator\u001b[0;34m(self, transaction, retry, timeout)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Helper method for :meth:`stream`.\"\"\"\u001b[39;00m\n\u001b[1;32m    215\u001b[0m request, expected_prefix, kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prep_stream(\n\u001b[1;32m    216\u001b[0m     transaction,\n\u001b[1;32m    217\u001b[0m     retry,\n\u001b[1;32m    218\u001b[0m     timeout,\n\u001b[1;32m    219\u001b[0m )\n\u001b[0;32m--> 221\u001b[0m response_iterator \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_client\u001b[39m.\u001b[39;49m_firestore_api\u001b[39m.\u001b[39;49mrun_query(\n\u001b[1;32m    222\u001b[0m     request\u001b[39m=\u001b[39;49mrequest,\n\u001b[1;32m    223\u001b[0m     metadata\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_client\u001b[39m.\u001b[39;49m_rpc_metadata,\n\u001b[1;32m    224\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    225\u001b[0m )\n\u001b[1;32m    227\u001b[0m \u001b[39mreturn\u001b[39;00m response_iterator, expected_prefix\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/google/cloud/firestore_v1/services/firestore/client.py:1309\u001b[0m, in \u001b[0;36mFirestoreClient.run_query\u001b[0;34m(self, request, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m metadata \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(metadata) \u001b[39m+\u001b[39m (\n\u001b[1;32m   1305\u001b[0m     gapic_v1\u001b[39m.\u001b[39mrouting_header\u001b[39m.\u001b[39mto_grpc_metadata(((\u001b[39m\"\u001b[39m\u001b[39mparent\u001b[39m\u001b[39m\"\u001b[39m, request\u001b[39m.\u001b[39mparent),)),\n\u001b[1;32m   1306\u001b[0m )\n\u001b[1;32m   1308\u001b[0m \u001b[39m# Send the request.\u001b[39;00m\n\u001b[0;32m-> 1309\u001b[0m response \u001b[39m=\u001b[39m rpc(\n\u001b[1;32m   1310\u001b[0m     request,\n\u001b[1;32m   1311\u001b[0m     retry\u001b[39m=\u001b[39;49mretry,\n\u001b[1;32m   1312\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m   1313\u001b[0m     metadata\u001b[39m=\u001b[39;49mmetadata,\n\u001b[1;32m   1314\u001b[0m )\n\u001b[1;32m   1316\u001b[0m \u001b[39m# Done; return the response.\u001b[39;00m\n\u001b[1;32m   1317\u001b[0m \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/google/api_core/gapic_v1/method.py:113\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[0;34m(self, timeout, retry, *args, **kwargs)\u001b[0m\n\u001b[1;32m    110\u001b[0m     metadata\u001b[39m.\u001b[39mextend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_metadata)\n\u001b[1;32m    111\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39mmetadata\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m metadata\n\u001b[0;32m--> 113\u001b[0m \u001b[39mreturn\u001b[39;00m wrapped_func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/google/api_core/retry.py:349\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    345\u001b[0m target \u001b[39m=\u001b[39m functools\u001b[39m.\u001b[39mpartial(func, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    346\u001b[0m sleep_generator \u001b[39m=\u001b[39m exponential_sleep_generator(\n\u001b[1;32m    347\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_initial, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maximum, multiplier\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_multiplier\n\u001b[1;32m    348\u001b[0m )\n\u001b[0;32m--> 349\u001b[0m \u001b[39mreturn\u001b[39;00m retry_target(\n\u001b[1;32m    350\u001b[0m     target,\n\u001b[1;32m    351\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_predicate,\n\u001b[1;32m    352\u001b[0m     sleep_generator,\n\u001b[1;32m    353\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_timeout,\n\u001b[1;32m    354\u001b[0m     on_error\u001b[39m=\u001b[39;49mon_error,\n\u001b[1;32m    355\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/google/api_core/retry.py:207\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, **kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m     next_attempt_time \u001b[39m=\u001b[39m datetime_helpers\u001b[39m.\u001b[39mutcnow() \u001b[39m+\u001b[39m datetime\u001b[39m.\u001b[39mtimedelta(\n\u001b[1;32m    204\u001b[0m         seconds\u001b[39m=\u001b[39msleep\n\u001b[1;32m    205\u001b[0m     )\n\u001b[1;32m    206\u001b[0m     \u001b[39mif\u001b[39;00m deadline \u001b[39m<\u001b[39m next_attempt_time:\n\u001b[0;32m--> 207\u001b[0m         \u001b[39mraise\u001b[39;00m exceptions\u001b[39m.\u001b[39mRetryError(\n\u001b[1;32m    208\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mDeadline of \u001b[39m\u001b[39m{:.1f}\u001b[39;00m\u001b[39ms exceeded while calling target function\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    209\u001b[0m                 timeout\n\u001b[1;32m    210\u001b[0m             ),\n\u001b[1;32m    211\u001b[0m             last_exc,\n\u001b[1;32m    212\u001b[0m         ) \u001b[39mfrom\u001b[39;00m \u001b[39mlast_exc\u001b[39;00m\n\u001b[1;32m    214\u001b[0m _LOGGER\u001b[39m.\u001b[39mdebug(\n\u001b[1;32m    215\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mRetrying due to \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, sleeping \u001b[39m\u001b[39m{:.1f}\u001b[39;00m\u001b[39ms ...\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(last_exc, sleep)\n\u001b[1;32m    216\u001b[0m )\n\u001b[1;32m    217\u001b[0m time\u001b[39m.\u001b[39msleep(sleep)\n",
      "\u001b[0;31mRetryError\u001b[0m: Deadline of 300.0s exceeded while calling target function, last exception: 429 Quota exceeded."
     ]
    }
   ],
   "source": [
    "'''calculates the rolling average maximum temperature \n",
    "    over a 7-day window for each location'''\n",
    "\n",
    "# Query all documents in the \"weather_data\" collection\n",
    "docs = db.collection_group(\"weather_data\").get()\n",
    "\n",
    "# Convert the documents to a pandas DataFrame\n",
    "data = []\n",
    "for doc in docs:\n",
    "    doc_data = doc.to_dict()\n",
    "    doc_data[\"id\"] = doc.id\n",
    "    data.append(doc_data)\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Convert the \"Date\" column to datetime format\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "\n",
    "# Calculate the rolling average maximum temperature over a 7-day window for each location\n",
    "rolling_avg = df.groupby(\"Location\")[\"MaxTemp\"].rolling(window=pd.Timedelta(\"7D\").days, min_periods=1).mean()\n",
    "df[\"RollingAvgMaxTemp\"] = rolling_avg.reset_index(0, drop=True)\n",
    "\n",
    "\n",
    "# Filter for the most recent 5 years of data since the dataset goes up to 2017, we will start in 2012\n",
    "recent_data = df[df[\"Date\"] > pd.Timestamp(year=2012, month=1, day=1)]\n",
    "\n",
    "# Get the days with the highest rolling average maximum temperature for each location\n",
    "max_temp_days = recent_data.groupby(\"Location\")[\"RollingAvgMaxTemp\"].idxmax()\n",
    "result = recent_data.loc[max_temp_days, [\"Location\", \"Date\", \"RollingAvgMaxTemp\"]]\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using window close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''retrieve the previous and next year's maximum temperature for each location'''\n",
    "\n",
    "# Define the collection name and field names\n",
    "collection_name = \"weather_data\"\n",
    "date_field = \"Date\"\n",
    "location_field = \"Location\"\n",
    "max_temp_field = \"MaxTemp\"\n",
    "\n",
    "# Define the date range for the query (most recent 5 years)\n",
    "start_date = \"2012-01-01\"\n",
    "end_date = \"2021-12-31\"\n",
    "\n",
    "# Query the Firestore collection for the relevant data\n",
    "query = db.collection(collection_name) \\\n",
    "           .where(date_field, \">=\", start_date) \\\n",
    "           .where(date_field, \"<=\", end_date) \\\n",
    "           .order_by(date_field, location_field)\n",
    "\n",
    "# Initialize variables to store the previous and next year's maximum temperatures\n",
    "prev_max_temps = {}\n",
    "next_max_temps = {}\n",
    "\n",
    "# Iterate over the query results and populate the prev_max_temps and next_max_temps dictionaries\n",
    "for doc in query.stream():\n",
    "    # Extract the document data\n",
    "    doc_data = doc.to_dict()\n",
    "    date = doc_data[date_field]\n",
    "    location = doc_data[location_field]\n",
    "    max_temp = doc_data[max_temp_field]\n",
    "\n",
    "    # Check if there is a previous year's maximum temperature for this location\n",
    "    prev_date = f\"{int(date[:4])-1}{date[4:]}\"\n",
    "    prev_query = db.collection(collection_name) \\\n",
    "                   .where(date_field, \"==\", prev_date) \\\n",
    "                   .where(location_field, \"==\", location) \\\n",
    "                   .limit(1)\n",
    "    prev_doc = next(iter(prev_query.stream()), None)\n",
    "    if prev_doc:\n",
    "        prev_max_temp = prev_doc.to_dict()[max_temp_field]\n",
    "        prev_max_temps[f\"{location}_{date}\"] = prev_max_temp\n",
    "\n",
    "    # Check if there is a next year's maximum temperature for this location\n",
    "    next_date = f\"{int(date[:4])+1}{date[4:]}\"\n",
    "    next_query = db.collection(collection_name) \\\n",
    "                   .where(date_field, \"==\", next_date) \\\n",
    "                   .where(location_field, \"==\", location) \\\n",
    "                   .limit(1)\n",
    "    next_doc = next(iter(next_query.stream()), None)\n",
    "    if next_doc:\n",
    "        next_max_temp = next_doc.to_dict()[max_temp_field]\n",
    "        next_max_temps[f\"{location}_{date}\"] = next_max_temp\n",
    "\n",
    "# Filter the data to include only the most recent year for each location\n",
    "most_recent_year = end_date[:4]\n",
    "filtered_data = [doc.to_dict() for doc in query.stream()\n",
    "                 if doc.to_dict()[date_field].startswith(most_recent_year)]\n",
    "\n",
    "# Add the previous and next year's maximum temperatures to the filtered data\n",
    "for doc in filtered_data:\n",
    "    key = f\"{doc[location_field]}_{doc[date_field]}\"\n",
    "    doc[\"PrevMaxTemp\"] = prev_max_temps.get(key, None)\n",
    "    doc[\"NextMaxTemp\"] = next_max_temps.get(key, None)\n",
    "\n",
    "# Print the filtered data with the previous and next year's maximum temperatures\n",
    "for doc in filtered_data:\n",
    "    print(doc)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "drill down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''retrieves all weather data documents from the \"weather_data\" collection \n",
    "    where the location is \"Sydney\" and the maximum temperature is greater than \n",
    "    or equal to 30'''\n",
    "\n",
    "# Define the collection and query\n",
    "collection_name = \"weather_data\"\n",
    "query = db.collection(collection_name).where(\"Location\", \"==\", \"Sydney\").where(\"MaxTemp\", \">=\", 30)\n",
    "\n",
    "# Retrieve the documents that match the query\n",
    "results = query.get()\n",
    "\n",
    "# Print the document IDs and data\n",
    "for doc in results:\n",
    "    print(f\"Document ID: {doc.id}\")\n",
    "    print(f\"Data: {doc.to_dict()}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "roll up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''retrieves the average maximum temperature \n",
    "    for each location in the \"weather_data\" collection'''\n",
    "# Define the collection and query\n",
    "collection_name = \"weather_data\"\n",
    "query = db.collection(collection_name).select([\"Location\", \"MaxTemp\"]).order_by(\"Location\")\n",
    "\n",
    "# Retrieve the documents and compute the summary\n",
    "results = query.stream()\n",
    "summaries = {}\n",
    "counts = {}\n",
    "for doc in results:\n",
    "    location = doc.get(\"Location\")\n",
    "    max_temp = doc.get(\"MaxTemp\")\n",
    "    if location not in summaries:\n",
    "        summaries[location] = max_temp\n",
    "        counts[location] = 1\n",
    "    else:\n",
    "        summaries[location] += max_temp\n",
    "        counts[location] += 1\n",
    "\n",
    "# Print the summary\n",
    "print(\"Location\\tAvg Max Temp\")\n",
    "for location, summary in summaries.items():\n",
    "    avg_max_temp = summary / counts[location]\n",
    "    print(f\"{location}\\t{avg_max_temp:.2f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''selects documents in the \"weather_data\" collection \n",
    "    where the temperature (which is the combination of min, max temp at 3am and temps at 9am) \n",
    "    is greater than 30 degrees'''\n",
    "# Create a Firestore client\n",
    "db = firestore.client()\n",
    "\n",
    "# Define the collection and query\n",
    "collection_name = \"weather_data\"\n",
    "query = db.collection(collection_name).where(\"MinTemp\", \">=\", 30).where(\"MaxTemp\", \">=\", 30).where(\"Temp3pm\", \">=\", 30).where(\"Temp9am\", \">=\", 30)\n",
    "\n",
    "# Retrieve the documents\n",
    "results = query.stream()\n",
    "\n",
    "# Print the documents\n",
    "for doc in results:\n",
    "    print(doc.to_dict())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''selects documents in the \"weather_data\" collection where the location is \"Albury\" \n",
    "    and the minimum temperature is less than or equal to 10 degrees'''\n",
    "# Define the collection and query\n",
    "collection_name = \"weather_data\"\n",
    "query = db.collection(collection_name).where(\"Location\", \"==\", \"Albury\").where(\"MinTemp\", \"<=\", 10)\n",
    "\n",
    "# Retrieve the documents\n",
    "results = query.stream()\n",
    "\n",
    "# Print the documents\n",
    "for doc in results:\n",
    "    print(doc.to_dict())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "combination of olap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''selects documents in the \"weather_data\" collection \n",
    "    where the location is either \"Albury\" or \"Melbourne\", \n",
    "    and the minimum temperature is less than or equal to 10 degrees'''\n",
    "# Define the collection and query\n",
    "collection_name = \"weather_data\"\n",
    "query = db.collection(collection_name).where(\"Location\", \"in\", [\"Albury\", \"Melbourne\"]).where(\"MinTemp\", \"<=\", 10)\n",
    "\n",
    "# Retrieve the documents\n",
    "results = query.stream()\n",
    "\n",
    "# Print the documents\n",
    "for doc in results:\n",
    "    print(doc.to_dict())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
